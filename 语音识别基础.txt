asrt核心逻辑：
    1、通过声学模型【采用深度卷积神经网络【DCNN】和连接时序分类【CTC】方法】，将声音转录为中文拼音；
    2、通过语言模型，将拼音序列转换为中文文本。

特征提取：
    将普通的wav语音信号通过分帧加窗等操作转换为神经网络需要的二维频谱图像信号，即语谱图。

模型：
    1、声学模型：DCNN+CTC。
    作用：用于实现将声学信号转换为拼音标签序列。
    工程：基于keras和tensorflow框架
    CTC解码：在声学模型的输出中，往往包含了大量连续重复的符号，因此需要将连续相同的符号合并为同一个符号，然后再去除静音分割标记符，得到最终实际的语音拼音符号序列

    2、语言模型：基于概率图的马尔可夫模型。
    作用：用于实现将拼音标签序列转换为最终对应的中文文本【即识别出来的文字】。拼音转文本的本质被建模为一条隐含马尔科夫链。

训练过程：
    0、定义声学模型【内含神经网络和损失函数】和优化器，获取语音模型
    1、加载训练数据
    2、编译调试损失函数和优化器
    3、对于输入数据进行特征提取
    4、计算单次迭代的单批训练的数据量【总量/批数】
    5、分迭代进行训练【每次迭代内，分批次训练。训练之前的输入数据有进行特征提取吗？】并保存具备迭代号标记的训练模型【保存模型方法只传入了文件名，模型数据在哪里呢？利用了tensorflow中的Model类，保存模型时只需传入文件名即可。一般保存模型保存的是训练得到的最佳【准确率最高或者误差最小】网络权重参数】
    6、保存最终训练模型

预测/识别过程：
    0、加载训练好的语音模型
    1、读取wav音频文件，输出矩阵语音数据
    2、对语音矩阵提取特征
    3、利用语音模型预测特征得出拼音结果索引
    4、加载字典拼音数据，依据索引获取最终识别的拼音结果
    5、利用语音模型将拼音结果翻译为中文

总结：
    1、训练和预测/识别阶段共性：对于输入音频数据进行同样的特征提取及预处理
    2、训练和预测/识别阶段不同之处：训练依据模型及优化器和输入特征及标签得出网络模型；识别依据训练好的模型进行识别预测

训练过程：
训练数据加载过程：见data_loader.py文件_load_data方法代码注释
特征提取和数据整形：见speech_features.py中类Spectrogram的run方法代码注释【特征算法处理，待学习】和speech_model.py文件_data_generator方法代码注释
分迭代【迭代内分批次】训练和保存模型：见speech_model.py文件train_model方法代码注释
保存模型【提问：分迭代保存模型和训练后保存模型有什么联系？为啥要在两个地方出现保存模型？】

评估过程：
评估数据加载过程：见data_loader.py文件_load_data方法代码注释
随机选取音频文件，进行模型预测：
    特征提取和数据整形：见speech_features.py中类Spectrogram的run方法代码注释和speech_model.py文件_data_generator方法代码注释
    模型预测：见keras_backend.py中类SpeechModel251BN的forward方法代码注释【预测数据，待学习】
    计算误差：见ops.py中的get_edit_distance方法代码注释【计算编辑距离，待学习】
    打印或保存误差及错误率信息

识别过程：
加载训练好的模型：利用tensorflow中的Model类load_weights方法
读取输入音频文件：读取单个音频文件
特征提取和数据整形：见speech_features.py中类Spectrogram的run方法代码注释【特征算法处理，待学习】和speech_model.py文件_data_generator方法代码注释
    1、给定窗长25ms，窗与窗之间的时移10ms
    2、计算窗长【所含音频数据元素个数，目前是400】及时移长度【所含音频数据元素个数，目前是160】和窗数【（音频数据总长度-单个窗长）/时移长度+1】
    3、从1遍历窗长：
        3.1、取当前待加窗的音频数据元素，音频段【帧】
        3.2、与汉明窗函数进行矩阵点乘运算
        3.3、进行fft快速傅里叶变换和取绝对值
        3.4、取一半元素作为当前音频段的特征提取结果，并收集
    4、对特征提取结果进行加1取对数【这个有什么用？】
        取对数的作用：
            1、缩小数据的绝对值，方便计算
            1.1、不会改变数据的相对关系
            2、取对数后，可以将乘法计算转换为加法计算【那是不是会影响原本的加法运算？】
模型预测：见keras_backend.py中类SpeechModel251BN的forward方法代码注释【预测数据，待学习】
获取拼音结果：将预测得到的拼音索引依赖拼音列表获取拼音结果
将拼音翻译为中文：利用N-Gram语言模型将拼音列表翻译为中文，见language_model3.py中的类ModelLanguage的pinyin_to_text方法
    1、输入为拼音序列
    2、加载N-Gram语言模型【拼音与汉字列表的字典pinyin_dict，单字与频次的字典model1，二字与频次的字典model2】
    3、遍历拼音序列，对当前拼音执行如下操作：
        3.1、如果当前拼音无法匹配到汉字【通过pinyin_dict和当前拼音来判断】，则丢弃；
        3.2、如果当前拼音为首字【1-真实的第一个拼音，或者2-前期中间结果的最后一个汉字与当前拼音匹配的汉字组成的二字序列没有出现在model2中，或者3-前期拼音都未匹配成功】，则匹配单字后，置出现概率皆为1【这里有个疑问：model1表示单字的出现频次，为什么这里将概率都置为1呢？而不用单字的出现频次来计算概率？】
            3.2.1、对于情况1-和3-，得到中间结果，遍历下一个拼音；
            3.2.2、对于情况2-，先将前期中间结果纳入到最终结果列表中，然后将当前拼音作为首字匹配，并将匹配结果的第一个元素纳入到结果列表中，最后将前期中间结果置为空列表，遍历下一个拼音。
        3.3、如果当前拼音正常匹配到中间结果中【前期中间结果的最后一个汉字与当前拼音匹配的汉字组成的二字序列有出现在model2中，则计算出现概率：（前期中间结果原始概率*二字序列频次）/当前拼音匹配单字在model1中频次，并将加入当前拼音对应汉字的新中间结果序列和其出现概率纳入新中间结果列表中，并对新中间结果列表按照元素的出现概率进行从大到小排序，并对其做长度阈值100截断处理，取前100个出现概率较大的元素】，则取新的中间结果列表作为前期中间结果，继续遍历下一个拼音；
    4、遍历完毕，判断此时中间结果列表是否为空，若非空，则取其第一个元素【出现概率最大的匹配结果】纳入到最终结果列表中

为什么要对语音信号做预处理？分帧加窗及特征提取。在进入神经网络时，有两点要求：矩阵化和真实反映语音特性【保持语音信号的信息完整性】。
    1、语音信号是一个非稳态、时变的信号。但具备短时不变性。
    声学知识：由于语音是由声门的激励脉冲通过声道形成，而声道，即人的口腔肌肉运动是缓慢的，所以在“短时间”内可以认为语音信号是稳态、时不变的信号。这个“短时间”一般指10~30ms。正是由于语音信号的“准稳态”特点，构成了语音信号的“短时分析技术”。
    分帧：一般帧长为10-30ms，对应语音信号的准稳态时长。
    加窗：分帧切割会导致帧与帧之间的信息损失，因此帧与帧之间会有重叠，以降低损失，但是重叠部分的信号有很负面影响呢？而加窗有什么作用呢？
    思考：
        1.1、为什么要考虑语音信号的时变和稳态特性呢？稳态的信号，信息具备完整性边界，我们要把语音信号用于神经网络训练，就应该做到两点：信号信息完整性【稳态时长为帧长，最大限度地保证局部信息完整性】和适配神经网络输入数据维数【分帧切割】。
        1.2、难道不可以直接把语音信号作为输入矩阵供神经网络训练使用吗？语音信号时长是不确定的，而神经网络的输入数据维数是固定的，二者不兼容。
    2、

目标：
    1、掌握语音识别基本工程步骤，能够独立编写代码实现；
    2、理解语音信号处理理论知识，包括：声学知识、信号处理知识、神经网络知识、误差函数知识；
    3、形成对神经网络应用到实际一般工程设计思路，追求优化思路并进行一定实践；